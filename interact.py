################
### Interact ###
################
# 03/11/2017
# interact.py
# version 1.1
#
# See Tutorial.pdf for details on installation, methods, usage and output files.
#
####################
### Changes log  ###
####################
#
#    v1.2 (12/06/2019)
#        - correct a bug related to matplotlib.pyplot import (reported by Michael Osborne, University of Montreal)
#    v1.1 (03/11/2017)
#        - added routines to process 1D spectra (initially designed for 2D spectra only):
#	      . the main workflow remains similar
#	      . dimension of spectra is automatically detected
#	      . in 1D spectra, chemical shifts and fwhm are estimated via topspin pp routines,
#		not by fitting
#    v1.0 (07/03/2017)
#        - 2D fit is optional (performed only if argument '--fwhm' is provided
#        - different models can be used to fit 2D spectra (Lor., Gauss., Gauss. with rotation)
#        - '--opt' argument introduced to update processing parameters (Python path,
#          model and initial fwhm value to fit 2D spectra, and nuclei-dependent coefficients)
#    v0.9.5 (21/02/2017)
#        - nuclei-dependent coefficients for calculation of euclidian distance are
#          automatically defined (as gamma_nuclei/gamma_1H)
#        - processing files for each signal are now saved in a 'tmp' subdirectory
#        - estimation of the resolution of 2D peaks in F1 & F2 by fitting a Lorentzian
#          model
#        - '--upd' argument introduced to update the result files when processing a novel
#          signal, otherwise results files are silently rewritten
#    v0.9 (16/01/2017)
#        - when '--nopp' option is used and _pp_res.txt has been edited manually, dwF1,
#          dwF2 and eucl. distance are recalculated automatically from F1 & F2 (and
#          _pp_res.txt is updated)
#        - sd of slope, initial ordinate and angle are estimated
#    v0.5 (14/12/2016)
#        - add linear regression of delta_omega_F1=a*delta_omega_F2+b
#        - add arguments '--kd' and/or '--slope' to run fitting
#        - add '--nopp' argument to fit data without running peak picking
#    v0.4 (04/11/2016)
#        - corrected a bug of v0.3
#        - annotation is now saved in the topspin peak list
#        - KD is estimated from experimental data
#        - folder 'res' is created in the experiment directory to save results
#    v0.3 (04/11/2016)
#        - automatically picks the peaks on the displayed window (via dpl)
#    v0.2 (02/11/2016)
#        - also returns the difference of chemical shifts compared to
#          the reference spectrum and the euclidian distance
#    v0.1 (21/10/2016)
#        - initial release
#
####################
#
#    Author: Pierre Millard, pierre.millard@insa-toulouse.fr
#    Copyright 2017, INRA
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
####################


##############################
# import modules & functions #
##############################

import math, os, sys, subprocess, re

# python code generated for data integration
pcode_Kd_fit = r"""# This code is automatically generated by Interact, do not edit
from __future__ import print_function
try:
  import os, matplotlib, math
  import matplotlib.pyplot
  import numpy as np
  from lmfit import minimize, Minimizer, Parameters, fit_report
except:
  f = open("fit_err.txt", "w")
  f.write("Error: some python modules are missing")
  f.close()
  exit()

col = [(31./255., 119./255., 180./255.), (214./255., 39./255., 40./255.)]

# range function for floats
def xfrange(start, stop, step):
    res = []
    i = 0
    while start + i * step < stop:
        res.append(start + i * step)
        i += 1
    return(res)

# calculate w=f(x, P, KD)
def simulate(p, x):
    P = p['P'].value if 'P' in p else $pini
    KD = p['KD'].value
    dmax = p['dmax'].value
    model = dmax*(P+x+KD - np.sqrt((P+x+KD)**2 - 4*P*x))/(2*P)
    return model

# cost function for kd estimation
def residual(p, x, data):
    model = simulate(p, x)
    return(data - model)

# measured data
ndims = $ndims
name = "$name"
conc = np.float_(np.array($conc))
w = np.float_(np.array($w))
P_ini = $pini
y = np.float_(np.array($x))
x = np.float_(np.array($y))
fc1 = 1./$coefF1
if ndims == 2:
    fc2 = 1./$coefF2

# working directory
os.chdir("$path")

# initialize parameters
p = Parameters()
p.add('dmax', value=$deltamax, min=0., max=1.e+6)
p.add('KD', value=1., min=0., max=1.e+6)
if P_ini == 0.:
  p.add('P', value=1., min=0., max=1.e+6)

# optimization
mini = Minimizer(residual, p, (conc, w))
result = mini.minimize()

# simulate data from the best parameters (100 data points)
ss = np.float_(np.array(xfrange(0.,max(conc)+1.,max(conc)/100.)))
ws = simulate(result.params, ss)

# linear regression (only when processing 2D spectra)
if ndims == 2:
	par, V = np.polyfit(x, y, 1, cov=True)
	m, c = par[0], par[1]
	sd_m, sd_c = np.sqrt(V[0][0]), np.sqrt(V[1][1])
	mcor = m/fc1*fc2
	q = math.atan(mcor)
	r = math.degrees(q)
	sd_q = q*((sd_m/fc1*fc2)/(math.sin(mcor)*math.cos(mcor)))
	sd_r = math.degrees(sd_q)

# plot fitting results in a pdf file
if ndims == 2:
	fig = matplotlib.pyplot.figure(figsize=(6, 8))
	G = matplotlib.gridspec.GridSpec(2,2)
elif ndims == 1:
	fig = matplotlib.pyplot.figure(figsize=(6, 4))
	G = matplotlib.gridspec.GridSpec(1,2)
# plot measured vs simulated data (Kd)
pan1 = matplotlib.pyplot.subplot(G[0, :])
pan1.scatter(conc, w, color=col[0], s=30) 
pan1.plot(ss, ws, color=col[1]) 
pan1.set_xlim(xmin=0)
pan1.set_ylim(ymin=0)
pan1.set_xlabel('ligand concentration')
pan1.set_ylabel('peak distance')
pan1.set_title(name)
# plot measured vs simulated data (lin regression, only for 2D spectra)
if ndims == 2:
	pan2 = matplotlib.pyplot.subplot(G[1, :])
	pan2.scatter(x, y, color=col[0], s=30) 
	pan2.plot(x, m*x + c, color=col[1])
	pan2.set_xlabel('F2 shift (ppm)')
	pan2.set_ylabel('F1 shift (ppm)')
# save plots
matplotlib.pyplot.tight_layout()
matplotlib.pyplot.savefig(name + "_fit.pdf", format='pdf') 

# save results (optimization process, confidence intervals, etc)
f = open(name + "_fit_res.txt", "w")
#if sys.version_info > (3, 0):
#    print(fit_report(result), end="", file=f)
#else:
#    print >> f, fit_report(result)
print(fit_report(result), end="", file=f)

# save lin results (optimization process, confidence intervals, etc)
if ndims == 2:
	out = "\n\n[[F1 vs F2 - linear fit]]\n"
	out += "    a: " + str(m) +  " +/- " + str(sd_m) + "\n"
	out += "    b: " + str(c) +  " +/- " + str(sd_c) + "\n"
	out += "    angle: " + str(r) +  " +/- " + str(sd_r)
	f.write(out)
f.close()
"""

pcode_2D_fit = r"""# This code is automatically generated by Interact, do not edit
try:
  from lmfit import Model
  import numpy as np
  import os, math, matplotlib
  import matplotlib.pyplot
except:
  f = open("2Dfit_err.txt", "w")
  f.write("Error: some python modules are missing")
  f.close()
  exit()

try:
  os.remove("$fres")
  os.remove("$pdf_reso")
except:
  pass

def lorentzian2D(dat, px, py, wx, wy, A):
  res = A * (2/(np.pi*np.sqrt(wx**2+wy**2))) / ((dat[:, 0]-px)**2/(wx/2)**2 + (dat[:, 1]-py)**2/(wy/2)**2 + 1)
  return(res)

def gaussian2D(dat, px, py, wx, wy, A):
  res = A/(2*np.pi*wx*wy) * np.exp(-((dat[:, 0]-px)**2/(2*wx**2) + (dat[:, 1]-py)**2/(2*wy**2)))
  return(res)

def gaussian2Drot(dat, px, py, wx, wy, A, theta):
  th = math.radians(theta)
  c_a = (np.cos(th)**2)/(2*wx**2) + (np.sin(th)**2)/(2*wy**2)
  c_b = -(np.sin(2*th))/(4*wx**2) + (np.sin(2*th))/(4*wy**2)
  c_c = (np.sin(th)**2)/(2*wx**2) + (np.cos(th)**2)/(2*wy**2)
  res = A * np.exp(-(c_a*(dat[:, 0]-px)**2-2*c_b*(dat[:, 0]-px)*(dat[:, 1]-py)+c_c*(dat[:, 1]-py)**2))
  return(res)

def getppm(data, axis):
  wx = sorted(list(set([i[axis] for i in data])))
  return(wx)

data = np.array($data)
model = $model
ffig = "$pdf_reso"

gmod = Model(model)
gmod.set_param_hint('px', value=$F2, min=min(data[:,0]), max=max(data[:,0]))
gmod.set_param_hint('py', value=$F1, min=min(data[:,1]), max=max(data[:,1]))
gmod.set_param_hint('wx', value=$resoi, min=1e-5, max=2.0)
gmod.set_param_hint('wy', value=$resoi, min=1e-5, max=2.0)
gmod.set_param_hint('A', value=max(data[:,2]), min=1e-5, max=1e+14)
if model == gaussian2Drot:
  gmod.set_param_hint('theta', value=0., min=-45, max=45)
params = gmod.make_params()
result = gmod.fit(data[:, 2], dat=data[:, 0:2], params=params)

sF2 = getppm(data, axis=1)
sF1 = getppm(data, axis=0)
lsF1 = len(sF1)
ln = len(data)/lsF1
Xp, Yp = np.meshgrid(sF2[::-1], sF1[::-1])
Z_mes = np.array([i[2] for i in data]).reshape(lsF1,ln)
Z_sim = result.best_fit.reshape(lsF1,ln)

# grid geometry
G = matplotlib.gridspec.GridSpec(2,2) 

# plot 2D fit
fig = matplotlib.pyplot.figure(figsize=(6, 8))
# panel 1
pan11 = matplotlib.pyplot.subplot(G[0, :])
CS = pan11.contour(Yp.T, Xp.T, Z_mes.T)
pan11.clabel(CS, inline=1, fontsize=7, fmt='%1.0f')
pan11.set_title('Experimental spectrum')
pan11.tick_params(axis='both', which='both', right='off', top='off', direction='out', labelsize=10)
ax = matplotlib.pyplot.gca()
ax.yaxis.tick_right()
ax.get_yaxis().get_major_formatter().set_useOffset(False)
ax.get_xaxis().get_major_formatter().set_useOffset(False)
ax.invert_yaxis()
ax.invert_xaxis()
# panel 2
pan12 = matplotlib.pyplot.subplot(G[1, :])
CSsim = pan12.contour(Yp.T, Xp.T, Z_sim.T, levels=CS.levels)
pan12.clabel(CSsim, inline=1, fontsize=7, fmt='%1.0f')
pan12.set_title('Simulated spectrum')
pan12.tick_params(axis='both', which='both', right='off', top='off', direction='out', labelsize=10)
ax = matplotlib.pyplot.gca()
ax.yaxis.tick_right()
ax.get_yaxis().get_major_formatter().set_useOffset(False)
ax.get_xaxis().get_major_formatter().set_useOffset(False)
ax.invert_yaxis()
ax.invert_xaxis()
# save
fig.tight_layout()
matplotlib.pyplot.savefig(ffig, format='pdf') 

# save report
report = str(result.fit_report()) + "\n\n" + str(result.best_values) + "\n\n" + str(result.best_fit)
f = open("$fres", "w")
f.write(report)
f.close() 
"""

tpy = r"""# This code is automatically generated by Interact, do not edit
from __future__ import print_function
try:
  import os, matplotlib, math
  import matplotlib.pyplot
  import numpy as np
  from lmfit import minimize, Minimizer, Parameters, fit_report, Model
  f = open("test_install.txt", "w")
  f.write("Test successfull.")
  f.close()
except:
  f = open("test_install.txt", "w")
  f.write("Error: some modules are missing in the system's Python interpreter.\nPlease install the required modules (see Interact documentation) and rerun the installation test.")
  f.close()
"""

def test():
  # test the Python interpreter installed on the system
  pyf = "ps_test.py"
  resf = "test_install.txt"
  # create python script
  f = open(pyf, "w")
  f.write(tpy)
  f.close()
  # run the script
  cmd = pyf
  if python_env != "":
    cmd = python_env.strip(" ") + ' ' + cmd
  cmd = cmd.replace("\\", "/")
  subprocess.Popen(cmd, shell=True).wait()
  # check if the output file is produced and get the results, otherwise raise an error
  try:
    f = open(resf, "r")
    err = f.read()
    f.close()
    n = 1 if "Error" in err else 0
  except:
		n, err = 1, "Error in the system's Python interpreter path.\nPlease check the path provided and rerun the Interact installation test."
  # remove tmp files
  try:
	  os.remove(pyf)
  except:
		pass
  try:
	  os.remove(resf)
  except:
		pass
  return((n, err))	

# create and run externally python code to fit the parameters
def fit(name, w, conc, x, y, spath, P_ini, ndims):
  # generate python code for KD estimation
  if ndims == 2:
  	drep = {"$ndims":str(ndims), "$w":str(w), "$conc":str(conc), "$coefF1":str(coefF1), "$coefF2":str(coefF2), "$name":name, "$path":spath.replace("\\", "/"), "$deltamax":str(max(w)), "$pini":str(P_ini), "$x":str(x), "$y":str(y)}
  	optcode = multiple_replace(pcode_Kd_fit, drep)
  elif ndims == 1:
  	drep = {"$ndims":str(ndims), "$w":str(w), "$conc":str(conc), "$coefF1":str(coefF1), "$coefF2":str(1.), "$name":name, "$path":spath.replace("\\", "/"), "$deltamax":str(max(w)), "$pini":str(P_ini), "$x":str(x), "$y":str(y)}
  	optcode = multiple_replace(pcode_Kd_fit, drep)
  optfile = os.path.join(spath, name + "_fit.py")
  f = open(optfile, "w")
  f.write(optcode)
  f.close()
  # run optimization
  cmd = '"' + optfile + '"'
  if python_env != "":
  	cmd = python_env.strip(" ") + ' ' + cmd
  cmd = cmd.replace("\\", "/")
  subprocess.Popen(cmd, shell=True).wait()

def xfrange(start, stop, step):
    res = []
    i = 0
    while start + i * step < stop:
        res.append(start + i * step)
        i += 1
    return(res)

def extract2D(F2m, F2p, F1m, F1p):
	result = GETPROCDATA2D(F2m, F2p, F1m, F1p)
	nr, nc = len(result[0]), len(result)
	out = []
	for i in range(len(result)):
	  doubleArray = result[i]
	  ic = F2p - i * (F2p - F2m) / nc
	  for k in range(len(doubleArray)):
	  	kc = F1p - k * (F1p - F1m) / nr
	  	out.append([ic, kc, doubleArray[k]])
	return(out)

def parse_resolution(fres):
	tmp_wx, tmp_wy, tmp_wt = ["none"]*4, ["none"]*4, ["none"]*4
	try:
	  f = open(fres, "r")
	  for l in f.readlines():
	  	if "    wx:" in l:
	  	  tmp_wx = filter(None, l.strip("\n").split(" "))
	  	if "    wy:" in l:
		 	  tmp_wy = filter(None, l.strip("\n").split(" "))
	  	if "    theta:" in l:
		 	  tmp_wt = filter(None, l.strip("\n").split(" "))
		f.close()
		res = [tmp_wx[1], tmp_wx[3], tmp_wy[1], tmp_wy[3], tmp_wt[1], tmp_wt[3]]
	except:
	  res = ["error"]*6 
	return(res)

def multiple_replace(text, drep):
    rx = re.compile('|'.join(map(re.escape, drep)))
    def one_xlat(match):
        return drep[match.group(0)]
    res = rx.sub(one_xlat, text)
    return(res)

def estimate_res(F2m, F2p, F1m, F1p, F2, F1, tmp_folder, pk, expnoi):
	fscript = os.path.join(tmp_folder, pk + "_" + expnoi + "_2Dfit.py").replace("\\", "/")
	fres = fscript.replace("_2Dfit.py", "_2Dfit_res.txt")
	pdfres = fscript.replace("_2Dfit.py", "_2Dfit_res.pdf")
	nDdata = extract2D(F2m, F2p, F1m, F1p)
	drep = {"$F1":str(F1), "$F2":str(F2), "$data":str(nDdata), "$fres":fres, "$pdf_reso":pdfres}
	out = multiple_replace(pcode_2D_fit, drep)
	f = open(fscript, "w")
	f.write(out)
	f.close()
	cmd = ""
	if python_env != "":
	  cmd = python_env.strip(" ") + ' '
	cmd += '"' + fscript + '"'
	cmd = cmd.replace("\\", "/")
	subprocess.Popen(cmd, shell=True).wait()
	reso = parse_resolution(fres)
	return(reso)

# parse fitting result file
def parse_fit(filen, P_ini):
	tmp_kd, tmp_p, tmp_d, tmp_a, tmp_b, tmp_Angle = ["none"]*4, ["none", str(P_ini), "NA (fixed)", "none"], ["none"]*4, ["none"]*4, ["none"]*4, ["none"]*4
	try:
		f = open(filen, "r")
		for l in f.readlines():
			if "    KD:" in l:
			  tmp_kd = filter(None, l.strip("\n").split(" "))
			if "    P:" in l:
			  tmp_p = filter(None, l.strip("\n").split(" "))
			if "    dmax:" in l:
			  tmp_d = filter(None, l.strip("\n").split(" "))
			if "    a:" in l:
			  tmp_a = filter(None, l.strip("\n").split(" "))
			if "    b:" in l:
			  tmp_b = filter(None, l.strip("\n").split(" "))
			if "    angle:" in l:
			  tmp_Angle = filter(None, l.strip("\n").split(" "))
		f.close()
		res = [tmp_kd[1], tmp_kd[3], tmp_d[1], tmp_d[3], tmp_p[1], tmp_p[3], tmp_a[1], tmp_a[3], tmp_b[1], tmp_b[3], tmp_Angle[1], tmp_Angle[3]]
	except:
	  res = ["error"]*12 
	return(res)

def load_plist(f_in):
	d_in = dict()
	f = open(f_in, 'r')
	for l in f:
		if l[0] != "#":
			k_v = l.strip('\n').split('\t')
			d_in[k_v[0]] = [float(k) for k in k_v[1:]]
	f.close()
	return(d_in)

def load_ppres(fin, ndims):
	res = parsef(fin)
	d_in, slist = res[0], res[1]
	# update slist (i.e. recalculate dwF1, dwF2 and eucl. distance from F1 & F2)
	slist_upd = updateSlist(slist, ndims)
	write_ppres(res_folder, slist_upd, ndims)
	return([d_in, slist_upd])

def parsef(fin):
  slist = []
  f = open(fin, "r")
  for l in f.readlines():
    el = l.strip("\n").split("\t")
    if (len(el) == 16 or len(el) == 13 or len(el) == 9 or len(el) == 7) and el[0] != "PeakName":
      slist.append(el)
  f.close()
  d_in = dict((y, []) for y in list(set([x[0] for x in slist])))
  return([d_in, slist])

def load_ppres_err(fin, ndims):
	if os.path.isfile(fin):
		try:
			tmp = load_ppres(fin, ndims)
			return(tmp)
		except:
		  ERRMSG(message = "Error when reading file '" + fin + "'.", title="Error", details=None, modal=1)
		  EXIT()
	else:
	  ERRMSG(message = "File '" + fin + "' not found.", title="Error", details=None, modal=1)
	  EXIT()

def write_fitres(res_folder, fit_res, ndims):
	outfit = "Data integration results\n\n"
	if len(fit_res) > 0:
		if ndims == 2:
			outfit += "PeakName\tKD\tKD_sd\tdelta_max\tdelta_max_sd\tP\tP_sd\ta\ta_sd\tb\tb_sd\ttheta\ttheta_sd\n" 
			outfit += "\n".join(i + "\t" + "\t".join(j for j in fit_res[i]) for i in fit_res)
		elif ndims == 1:
			outfit += "PeakName\tKD\tKD_sd\tdelta_max\tdelta_max_sd\tP\tP_sd\t\n"
			outfit += "\n".join(i + "\t" + "\t".join(j for j in fit_res[i][0:6]) for i in fit_res)
	else:
		outfit += "No results."
	foutfit = os.path.join(res_folder, "_fit.txt").replace("\\", "/")
	f = open(foutfit, "w")
	f.write(outfit)
	f.close()
	return(outfit)

def updateSlist(slist, ndims):
  slist_upd = []
  for i,p in enumerate(slist):
  	if p[1] != "none":
  		try:
  			if ndims == 2:
  				if p[3] == "0":
  					wF1ref, wF2ref = float(p[4]), float(p[5])
  				dwF1, dwF2 = float(p[4]) - wF1ref, float(p[5]) - wF2ref
  				euc_dist = calc_d(dwF1, dwF2, coefF1, coefF2)
  			elif ndims == 1:
  				if p[3] == "0":
  					wF1ref = float(p[4])
  				dwF1 = float(p[4]) - wF1ref
  				euc_dist = abs(dwF1*coefF1)
  		except:
  		  ERRMSG(message = "Error in _pp.txt (line " + str(i+1) + ").\nValues of chemical shift(s) (F1 and/or F2) for signal '" + p[0] + "' in experiment '" + p[1] + "' are incorrect (float expected).", title="Error", details=None, modal=1)
  		  EXIT()
  		if ndims == 2:
  			p_upd = [p[i] for i in range(0,6)] + [dwF1, dwF2, euc_dist] + [p[i] for i in range(9,16)]
  		elif ndims == 1:
  			p_upd = [p[i] for i in range(0,5)] + [dwF1, euc_dist] + [p[i] for i in range(7,9)]
  	else:
  	  p_upd = p
  	slist_upd.append(p_upd)
  return(slist_upd)

def calc_d(dwF1, dwF2, coefF1, coefF2):
	euc_dist = math.sqrt(0.5*((coefF1 * dwF1)**2 + (coefF2 * dwF2)**2))
	return(euc_dist)

def write_ppres(res_folder, slist, ndims):
	outpp = "Peak picking results\n\n"
	if ndims == 2:
		outpp += "PeakName\tPeakID\tExpno\tLigand conc.\tF1 (ppm)\tF2 (ppm)\tdwF1 (ppm)\tdwF2 (ppm)\tEuclidian dist.\tIntensity\tresF1\tresF1_sd\tresF2\tresF2_sd\tphi\tphi_sd\n"
	elif ndims == 1:
		outpp += "PeakName\tPeakID\tExpno\tLigand conc.\tF1 (ppm)\tdwF1 (ppm)\tEuclidian dist.\tIntensity\tresF1\n"
	outpp += "\n".join("\t".join(str(j) for j in i) for i in slist)
	fout = os.path.join(res_folder, "_pp.txt").replace("\\", "/")
	f = open(fout, "w")
	f.write(outpp)
	f.close()
	return(outpp)

def Pwin():
	ask_p = INPUT_DIALOG("Interact", "Enter protein concentration (0 to estimate by fitting).", ["Protein conc."], ["0"], [""], ["1"])
	if ask_p == None:
		EXIT()
	try:
		P_ini = float(ask_p[0])
	except:
		ERRMSG(message = "Protein concentration must be a positive number.", title="Error", details=None, modal=1)
		EXIT()
	if P_ini < 0:
	  ERRMSG(message = "Protein concentration must be a positive number.", title="Error", details=None, modal=1)
	  EXIT()
	return(P_ini)

def peak_picking(F1m, F1p, F2m, F2p):
  # update peak picking window & pick the most intense peak
  #XCMD("F1P " + str(F2p) + " " + str(F1p))
  PUTPAR("2 F1P", str(F2p))
  PUTPAR("1 F1P", str(F1p))
  #XCMD("F2P " + str(F2m) + " " + str(F1m))
  PUTPAR("2 F2P", str(F2m))
  PUTPAR("1 F2P", str(F1m))
  #XCMD("PPMPNUM 1")
  PUTPAR("PPMPNUM", "1")
  # run peak picking silently
  XCMD("pp append nodia")

def peak_picking1D(F1m, F1p):
  # update peak picking window & pick the most intense peak
  PUTPAR("F1P", str(F1p))
  PUTPAR("F2P", str(F1m))
  fullrange = putil.DataChecks.getNMRDataOfSelectedFramePrintMsg().getFullPhysicalRange()
  newRange = fullrange
  newRange[0].setStart(F1p)
  newRange[0].setEnd(F1m)
  newRange[0].setUnit("ppm")
  XCMD(".zx", 1, newRange)
  # run peak picking silently
  XCMD("pps")

def updateXML(icurdata, pk, po, ndims):
  pk_list_f = os.path.join(icurdata[3], icurdata[0], icurdata[1], 'pdata', icurdata[2], 'peaklist.xml').replace("\\", "/")
  if ndims == 2:
  	searched_field = '<Peak2D F1="%0.4f" F2="%0.4f"' % (po[1], po[0])
  elif ndims == 1:
  	searched_field = '<Peak1D F1="%0.6f"' % (po)
  upd_pk_list_f = []
  f = open(pk_list_f, 'r')
  for l in f.readlines():
  	if searched_field in l and "annotation=" not in l:
  	  upd_l = searched_field + ' annotation="' + pk + '"'
  	  l = l.replace(searched_field, upd_l)
  	upd_pk_list_f.append(l)
  f.close()
  f = open(pk_list_f, 'w')
  f.write(''.join(upd_pk_list_f))
  f.close()
    
def upd_slist(fin, slist, ndims):
  lpp_old = load_ppres(fin, ndims)
  d_in_old, slist_old = lpp_old[0], lpp_old[1]
  lmeta = [(l[0], l[2]) for l in slist]
  tmp, app = [], []
  for v in slist_old:
  	if (v[0], v[2]) in lmeta:
  	  m = lmeta.index((v[0], v[2]))
  	  tmp.append(slist[m])
  	  app.append(m)
  	else:
  	  tmp.append(v)
  lmetan = list(set([i for i in range(0,len(lmeta))]) - set(app))
  tmp += [slist[i] for i in lmetan]
  return(tmp)

def upd_fitres(fin, fit_res):
  lfit_old = parsef(fin)
  for i in lfit_old[1]:
  	if i[0] not in fit_res.keys():
  	  fit_res[i[0]] = i[1:]
  return(fit_res)

def createDic():
	try:
	  XCMD("dpl")
	  F2p = float(GETPAR("F1P", axis = 2))
	  F1p = float(GETPAR("F1P", axis = 1))
	  F2m = float(GETPAR("F2P", axis = 2))
	  F1m = float(GETPAR("F2P", axis = 1))
	  result = INPUT_DIALOG("Interact", "Peak name.", ["Annotation = "], ["Ala_227"], [""], ["1"])
	  d_in = {result[0]:[F1m, F1p, F2m, F2p]}
	  return(d_in)
	except:
	  return(None)

def createDic1D():
	try:
	  XCMD("dpl")
	  F1p = float(GETPAR("F1P", axis = 1))
	  F1m = float(GETPAR("F2P", axis = 1))
	  result = INPUT_DIALOG("Interact", "Peak name.", ["Annotation = "], ["Ala_227"], [""], ["1"])
	  d_in = {result[0]:[F1m, F1p]}
	  return(d_in)
	except:
	  return(None)

def initialize(options):
	try:
		options = readOpt(options)
	except:
		writeOpt(options)
	return(options)

def readOpt(options):
	optfn = os.path.join(os.path.dirname(sys.argv[0]), "interact_opt.txt").replace("\\", "/")
	optf = open(optfn, 'r')
	for l in optf.readlines():
		li = l.strip("\n").split("\t")
		if li[0] in options.keys():
		  options[li[0]] = li[1]
	optf.close()
	options = parseOpt(options)
	return(options)

def writeOpt(options):
  optfn = os.path.join(os.path.dirname(sys.argv[0]), "interact_opt.txt").replace("\\", "/")
  optt = "\n".join([k + "\t" + str(v) for k, v in options.items()])
  optf = open(optfn, 'w')
  optf.write(optt)
  optf.close()

def parseOpt(options):
	if options["python_path"] != "" and not os.path.isfile(options["python_path"]):
	  ERRMSG(message = "Python path not found.", title="Error", details=None, modal=1)
	  EXIT()
	if options["model"] not in ['gaussian2Drot', 'gaussian2D', 'lorentzian2D']:
	  ERRMSG(message = "Model must be 'gaussian2Drot', 'gaussian2D', or 'lorentzian2D'.", title="Error", details=None, modal=1)
	  EXIT()
	try:
	  options["fwhm_ini"] = float(options["fwhm_ini"])
	except:
	  ERRMSG(message = "Initial FWHM value must be a positive float.", title="Error", details=None, modal=1)
	  EXIT()
	try:
	  options["nuclei"] = eval(options["nuclei"])
	  if type(options["nuclei"]) != type(dict()):
	    ERRMSG(message = "Information on nuclei must be a python dictionary.", title="Error", details=None, modal=1)
	    EXIT()
	except:
	  ERRMSG(message = "Information on nuclei must be a python dictionary.", title="Error", details=None, modal=1)
	  EXIT()
	return(options)

def modifyOpt(options):
	optold = initialize(options)
	diagOpt = INPUT_DIALOG("Interact", "Modify processing options.", ["2D fitting model", "python path", "fwhm ini", "nuclei"], [optold["model"], optold["python_path"], str(optold["fwhm_ini"]), str(optold["nuclei"])], ["", "", "", ""], ["1", "1", "1", "1"])
	if diagOpt != None:
	  kopt = ["model", "python_path", "fwhm_ini", "nuclei"]
	  for o,v in enumerate(kopt):
	    optold[v] = diagOpt[o]
	  opt_parsed = parseOpt(optold)
	  writeOpt(opt_parsed)
	EXIT()

##################
# run processing #
##################

# default parameters
opt_ini = {"model":"gaussian2Drot", "python_path":"", "fwhm_ini":'0.02', "nuclei":'{"1H":1.0, "13C":0.25, "15N":0.1, "31P":0.4}'}
# load user-defined parameters (default values are used if none declared)
options = initialize(opt_ini) 
python_env = options["python_path"]
model = options["model"]
Bio_Nuc = options["nuclei"]
fwhm = options["fwhm_ini"]

# test installation ?
if "--test" in sys.argv:
	rtest = test()
	if rtest[0] == 0:
		MSG(message = "Interact is successfully installed on this system.", title="Interact installation test")
		EXIT()
	else:
	  ERRMSG(message = rtest[1], title="Error", details=None, modal=1)
	  EXIT()

# modify Interact options
if "--opt" in sys.argv:
	modifyOpt(options)
	EXIT()

# check if multiple display is active
if SELECTED_WINDOW().isMultipleDisplayActive():
  ERRMSG(message = "Please exit multiple display before running Interact.", title="Error", details=None, modal=1)
  EXIT()

# check spectrum dimension
if GETPROCDIM() == 2:
	ndims = 2
elif GETPROCDIM() == 1:
	ndims = 1
else:
  ERRMSG(message = "The spectrum to process must have 1 or 2 dimensions.", title="Error", details=None, modal=1)
  EXIT()

# weighting coefficients (for F1 & F2) used to calculate the euclidian distance, as:
#    dist = sqrt(coefF1 * delta_omega_F1**2 + coefF2 * delta_omega_F2**2)
# automatically set these coefficients from nuclei
try:
	coefF1 = Bio_Nuc[GETPARSTAT("NUC1", axis=1)]
except:
  ERRMSG(message = "Unknown nucleus '" + GETPARSTAT("NUC1", axis=1) + "' in dimension F1.\nTo declare this nucleus in the processing parameters, run the command:\n\ninteract --opt", title="Error", details=None, modal=1)
  EXIT()
if ndims == 2:
	try:
			coefF2 = Bio_Nuc[GETPARSTAT("NUC1", axis=2)]
	except:
		  ERRMSG(message = "Unknown nucleus '" + GETPARSTAT("NUC1", axis=2) + "' in dimension F2.\nTo declare this nucleus in the processing parameters, run the command:\n\ninteract --opt", title="Error", details=None, modal=1)
		  EXIT()

# run peack picking ?
runPP = False if "--nopp" in sys.argv else True

# run fitting ?
isFit = False if "--noint" in sys.argv else True

# estimate resolution ?
isPW = True if "--fwhm" in sys.argv else False
if isPW:
  pcode_2D_fit = pcode_2D_fit.replace("$model", model).replace("$resoi", str(fwhm))

# update existing results files ?
isUpd = True if "--upd" in sys.argv else False

# raise an error if both arguments '--nopp' and '--noint' are provided
if runPP == False and isFit == False:
  ERRMSG(message = "No routine to run, please remove --nopp and/or --noint arguments.", title="Error", details=None, modal=1)
  EXIT()

# get current dataset & list expnos
current_dataset = CURDATA()
expnos = os.listdir(os.path.join(current_dataset[3], current_dataset[0]).replace("\\", "/"))
if "res" in expnos:
  expnos.remove("res")

# create output directories (res & tmp)
res_folder = os.path.join(current_dataset[3], current_dataset[0], "res").replace("\\", "/")
if not os.path.exists(res_folder):
	os.mkdir(res_folder)
tmp_folder = os.path.join(res_folder, "tmp")
if not os.path.exists(tmp_folder):
	os.mkdir(tmp_folder)

##########################################
#### 1D spectra processing routine
##########################################
if ndims == 1:
	# just load '_pp.txt' for fitting  (without peak picking)
	if runPP == True:
	  # get remaining arguments (expected to be peak database)
	  la = [sys.argv[i] for i in range(1, len(sys.argv)) if sys.argv[i][0:2] != "--"]
	  # display window to enter parameters for a single signal
	  if len(la) == 0:
		d_in = createDic1D()
		if d_in == None:
		  EXIT()
	  # load the database of peaks to process
	  elif len(la) == 1:
		f_in = la[0]
		if os.path.isfile(f_in):
			try:
				d_in = load_plist(f_in)
			except:
				ERRMSG(message = "Error when reading file '" + f_in + "'.", title="Error", details=None, modal=1)
				EXIT()
		else:
			ERRMSG(message = "File '" + f_in + "' not found.", title="Error", details=None, modal=1)
			EXIT()
	  elif len(la) > 1:
		ERRMSG(message = "Too many arguments.", title="Error", details=None, modal=1)
		EXIT()
		# if d_in is empty
		if len(d_in) == 0:
		  ERRMSG(message = "No signal to process.", title="Error", details=None, modal=1)
		  EXIT()
	  # get the number of expnos to process
	  ask_n = INPUT_DIALOG("Interact", "", ["Number of expno"], [str(len(expnos))], [""], ["1"])
	  if ask_n == None:
		EXIT()
	  try:
		  nexpo = int(ask_n[0])
	  except:
		  ERRMSG(message = "Number of experiments to process must be a positive integer.", title="Error", details=None, modal=1)
		  EXIT()
	  if nexpo < 1:
		  ERRMSG(message = "Number of experiments to process must be a positive integer.", title="Error", details=None, modal=1)
		  EXIT()
	  # get protein concentration for Kd estimation (free parameter if 0)
	  if isFit == True:
		P_ini = Pwin()
	  # ask for confirmation
	  val = CONFIRM("Ok", "Process the following expnos ?\n" + "\n".join(x for x in expnos[0:nexpo]))
	  if val == None:
		EXIT()
	  # run peak picking & spectrum annotation
	  icurdata = current_dataset
	  slist = []
	  # for each peak to process
	  for pk,v in d_in.items():
		# get the window boundary
		F1m, F1p = v[0], v[1]
		for expnoi in expnos[0:nexpo]:
		  SHOW_STATUS("Processing peak '" + pk + "' in expno '" + str(expnoi) + "'...")
		  # load expno (ask for the procno if several procno exists)
		  icurdata[1] = expnoi
		  RE(icurdata, show="n")
		  # get current peak list
		  #listp_ini = GETPEAKSARRAY()
		  #if listp_ini == None:
		  #  listp_ini = [])
		  #tf = [(peak.getRealIntensity(), peak.getPositions()) for peak in listp_ini]
		  # get the ligand concentration from the expno name (see Guy's standardized experiments' names)
		  concentration = int(expnoi[1:])
		  peak_picking1D(F1m, F1p)
		  # parse results
		  listp = GETPEAKSARRAY()
		  if listp == None:
			slist.append([pk, "none", expnoi, concentration] + ["none"]*5)
		  else:
			# get the last peak picked, with highest intensity
			spec = GETPROCDATA(F1m, F1p)
			ppm = spec.index(max(spec))
			interv = (F1p-F1m)/(len(spec)-1)
			ppm_pk = (F1p-ppm*interv)
			dpol = [abs(peak.getPositions()[0]-ppm_pk) for peak in listp]
			idpk = dpol.index(min(dpol))
			if dpol[idpk] > 2*interv:
				slist.append([pk, "none", expnoi, concentration] + ["none"]*5)
			else:
				peak = listp[idpk]
				# get chemical shifts
				# as a reminder, to list all peak attributes: dir(peak)
				po = peak.getPositions()[0]
				# identify chemical shifts of the reference expno (no ligand added) defined as the first expno
				if expnoi == expnos[0]:
					wF2ref = po
				# calculate differences of chemical shifts & euclidian distance compared to the ref
				dwF2 = float(po) - wF2ref
				euc_dist = abs(dwF2*coefF1)
				# get resolution
				if isPW:
					reso = peak.getHalfWidth()
				else:
					reso = ["nd"]
				# append results
				slist.append([pk, peak.getPeakID()+1, expnoi, concentration, po, dwF2, euc_dist, peak.getRealIntensity(), reso])
				# update topspin annotation by modifying the xml file
				updateXML(icurdata, pk, po, 1)
	  # go back to the initial dataset
	  RE(current_dataset, show="n")
	  # append pp results to file _pp.txt if it exists
	  if isUpd:
			try:
			  fin = os.path.join(res_folder, "_pp.txt").replace("\\", "/")
			  if os.path.isfile(fin):
				slist = upd_slist(fin, slist, 1)
			except:
			  pass
	  # save pp results
	  outpp = write_ppres(res_folder, slist, 1)
	  out_all = outpp + "\n\n"
	  # done
	  SHOW_STATUS("Peak picking finished")
	else:
		fin = os.path.join(res_folder, "_pp.txt").replace("\\", "/")
		lpp = load_ppres_err(fin, 1)
		d_in, slist = lpp[0], lpp[1]
		if isFit == True:
			P_ini = Pwin()
		out_all = ""
	# run fitting
	if isFit == True:
		fit_res = {}
		for pk,v in d_in.items():
			SHOW_STATUS("Fitting peak '" + pk + "'...")
			# estimate KD for the current signal
			filtered = [l for l in slist if l[0]==pk and l[6]!="none"]
			if len(filtered) > 1:
			  conc = [l[3] for l in filtered]
			  x = [l[6] for l in filtered]
			  y = [l[7] for l in filtered]
			  w = [l[6] for l in filtered]
			  fit(pk, w, conc, x, y, tmp_folder, P_ini, 1)
			  # parse fitting results
			  fitf = os.path.join(tmp_folder, pk + "_fit_res.txt").replace("\\", "/")
			  fit_res[pk] = parse_fit(fitf, P_ini) 
			else:
			  fit_res[pk] = ["undetermined"]*9 
		# append fitting results to the existing _fit.txt file if it exists
		if isUpd:
			try:
			  fin = os.path.join(res_folder, "_fit.txt").replace("\\", "/")
			  if os.path.isfile(fin):
				fit_res = upd_fitres(fin, fit_res)
			except:
			  pass
		# save fitting results
		outfit = write_fitres(res_folder, fit_res, 1)
		out_all += outfit



##########################################
#### 2D spectra processing routine
##########################################
if ndims == 2:
	# just load '_pp.txt' for fitting  (without peak picking)
	if runPP == True:
	  # get remaining arguments (expected to be peak database)
	  la = [sys.argv[i] for i in range(1, len(sys.argv)) if sys.argv[i][0:2] != "--"]
	  # display window to enter parameters for a single signal
	  if len(la) == 0:
		d_in = createDic()
		if d_in == None:
		  EXIT()
	  # load the database of peaks to process
	  elif len(la) == 1:
		f_in = la[0]
		if os.path.isfile(f_in):
			try:
				d_in = load_plist(f_in)
			except:
				ERRMSG(message = "Error when reading file '" + f_in + "'.", title="Error", details=None, modal=1)
				EXIT()
		else:
			ERRMSG(message = "File '" + f_in + "' not found.", title="Error", details=None, modal=1)
			EXIT()
	  elif len(la) > 1:
		ERRMSG(message = "Too many arguments.", title="Error", details=None, modal=1)
		EXIT()
		# if d_in is empty
		if len(d_in) == 0:
		  ERRMSG(message = "No signal to process.", title="Error", details=None, modal=1)
		  EXIT()
	  # get the number of expnos to process
	  ask_n = INPUT_DIALOG("Interact", "", ["Number of expno"], [str(len(expnos))], [""], ["1"])
	  if ask_n == None:
		EXIT()
	  try:
		  nexpo = int(ask_n[0])
	  except:
		  ERRMSG(message = "Number of experiments to process must be a positive integer.", title="Error", details=None, modal=1)
		  EXIT()
	  if nexpo < 1:
		  ERRMSG(message = "Number of experiments to process must be a positive integer.", title="Error", details=None, modal=1)
		  EXIT()
	  # get protein concentration for Kd estimation (free parameter if 0)
	  if isFit == True:
		P_ini = Pwin()
	  # ask for confirmation
	  val = CONFIRM("Ok", "Process the following expnos ?\n" + "\n".join(x for x in expnos[0:nexpo]))
	  if val == None:
		EXIT()
	  # run peak picking & spectrum annotation
	  icurdata = current_dataset
	  slist = []
	  # for each peak to process
	  for pk,v in d_in.items():
		# get the window boundary
		F1m, F1p, F2m, F2p = v[0], v[1], v[2], v[3]
		for expnoi in expnos[0:nexpo]:
		  SHOW_STATUS("Processing peak '" + pk + "' in expno '" + str(expnoi) + "'...")
		  # load expno (ask for the procno if several procno exists)
		  icurdata[1] = expnoi
		  RE(icurdata, show="n")
		  # get the ligand concentration from the expno name (see Guy's standardized experiments' names)
		  concentration = int(expnoi[1:])
		  peak_picking(F1m, F1p, F2m, F2p)
		  # parse results
		  listp = GETPEAKSARRAY()
		  if listp == None:
			slist.append([pk, "none", expnoi, concentration] + ["none"]*10)
		  else:
			# get the last peak picked
			peak = listp[-1]
			# get chemical shifts
			po = peak.getPositions()
			# just check that the last peak picked is within the window defined by the user
			if F2m <= po[0] <= F2p and F1m <= po[1] <= F1p:
			  # identify chemical shifts of the reference expno (no ligand added) defined as the first expno
			  if expnoi == expnos[0]:
				wF1ref, wF2ref = po[1], po[0]
			  # calculate differences of chemical shifts & euclidian distance compared to the ref
			  dwF1, dwF2 = float(po[1]) - wF1ref, float(po[0]) - wF2ref
			  euc_dist = calc_d(dwF1, dwF2, coefF1, coefF2)
			  # estimate resolution by 2D fitting to a 2D lorentzian function
			  if isPW:
				reso = estimate_res(F2m, F2p, F1m, F1p, po[0], po[1], tmp_folder, pk, expnoi)
			  else:
				reso = ["nd", "nd", "nd", "nd", "nd", "nd"]
			  # append results
			  slist.append([pk, peak.getPeakID()+1, expnoi, concentration, po[1], po[0], dwF1, dwF2, euc_dist, peak.getIntensity()] + reso)
			  # update topspin annotation by modifying the xml file
			  updateXML(icurdata, pk, po, 2)
			else:
			  slist.append([pk, "none", expnoi, concentration] + ["none"]*12)
	  # go back to the initial dataset
	  RE(current_dataset, show="n")
	  # append pp results to file _pp.txt if it exists
	  if isUpd:
			try:
			  fin = os.path.join(res_folder, "_pp.txt").replace("\\", "/")
			  if os.path.isfile(fin):
				slist = upd_slist(fin, slist, 2)
			except:
			  pass
	  # save pp results
	  outpp = write_ppres(res_folder, slist, 2)
	  out_all = outpp + "\n\n"
	  # done
	  SHOW_STATUS("Peak picking finished")
	else:
		fin = os.path.join(res_folder, "_pp.txt").replace("\\", "/")
		lpp = load_ppres_err(fin, 2)
		d_in, slist = lpp[0], lpp[1]
		if isFit == True:
			P_ini = Pwin()
		out_all = ""
	# run fitting
	if isFit == True:
		fit_res = {}
		for pk,v in d_in.items():
			SHOW_STATUS("Fitting peak '" + pk + "'...")
			# estimate KD for the current signal
			filtered = [l for l in slist if l[0]==pk and l[6]!="none"]
			if len(filtered) > 1:
			  conc = [l[3] for l in filtered]
			  x = [l[6] for l in filtered]
			  y = [l[7] for l in filtered]
			  w = [l[8] for l in filtered]
			  fit(pk, w, conc, x, y, tmp_folder, P_ini, 2)
			  # parse fitting results
			  fitf = os.path.join(tmp_folder, pk + "_fit_res.txt").replace("\\", "/")
			  fit_res[pk] = parse_fit(fitf, P_ini) 
			else:
			  fit_res[pk] = ["undetermined"]*12 
		# append fitting results to the existing _fit.txt file if it exists
		if isUpd:
			try:
			  fin = os.path.join(res_folder, "_fit.txt").replace("\\", "/")
			  if os.path.isfile(fin):
				fit_res = upd_fitres(fin, fit_res)
			except:
			  pass
		# save fitting results
		outfit = write_fitres(res_folder, fit_res, 2)
		out_all += outfit



SHOW_STATUS("Processing finished")

# display results
VIEWTEXT(title="Interact report", header="results", text=out_all)

